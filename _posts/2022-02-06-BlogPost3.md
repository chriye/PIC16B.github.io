---
layout: post
title: Blog Post 3
---

In this blog post, we'll find movies or shows that you might like based on your favorite moive or show. Through out the blog post, you'll know how to get data from website by scraping!! Let's get started!!

# Overview

In our real life, there're lot of things recommand to us from their systems. Here, we try to create a simple system that recommand movies or shows that you might interested in. The idea would be we first find the actors and their movies or shows as an actor. And then we rank movies and shows based on number of shared actors. The more shared actors, the higher ranking would be.

The main website that we'll use here will be *"https://www.imdb.com/"*. All the other websites that we'll use later are an extension of it.

# 1. Set up

## Installation

Install **scrapy** module in your Anaconda's working environment

## Locate a IMDB Page

Choose your favorite movie or show in IMDB. Save the link.

## Create a folder

Open a terminal in your repository and run the following code.

```python
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

The first line of above code is to activate PIC16B anaconda environment.
The second line is to create a project called IMDB_scraper that for scrapying. Once you created it, there're files and folder that created automatically.
The third line is to change the directory to IMDB_scraper

## Edit settings.py

In order to prevent you from downloading too much data, please add this line in settings.py.

`
CLOSESPIDER_PAGECOUNT = 20
`

Remember to delete it after you ensure the code is doing what you're intend to do.



# 2. Access data by scraping

## Set up

- Create a file called 'imdb_spider.py' under spiders folder
- Import a scrapy module

`
import scrapy
`

- Create a class named 'ImdSpider'. Inside the class, please copy the following lines.

```python
class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'

    start_urls = ['https://www.imdb.com/title/tt10872600/']
```

Replace 'https://www.imdb.com/title/tt10872600/' by your favorite movie or show IMDB url.

Then we'll write three function in the following three sections under the class.


## parse(self, response)

This function tells what scrapy to do. 

In this function, we want to navigate to **All cast & crew**. First, by looking at the pattern of **All cast & crew** url and **start_urls**, we could add *fullcredits* at the end of **start_urls** to get the **All cast & crew** url. In order to do this, we could command *response.urljoin('fullcredits')* to achieve it. As you noticed, we use **response** to call the urljoin. **response** refers to the url that passed to the function. Here, the refered url is **start_urls**. Then we want to call parse_full_credits() function and pass the **All cast & crew** url to it. Here, we use command *yield scrapy.Request(cast_crew, callback = self.parse_full_credits)* to achieve this. 

### Code:

```python
def parse(self, response):
    '''
    get the favorite movie's 'All cast & crew' link.
    call parse_full_function and pass the link to it.
    '''
    cast_crew = response.urljoin('fullcredits')
    yield scrapy.Request(cast_crew, callback = self.parse_full_credits)
```


## parse_full_credits(self, response)

We assume that we start on **All cast & crew** page.

In this function, we want to access all actors and pass their link to parse_actor_page() function. 

### Discover

As you notice, when you click a actor's name, it will navigate you to his page. Next, we'll need to find the url by scrapying. 

A tool that we need here is called **Developer Tools**, which comes with google chrome. Once you click it, there's a window on the right-hand side of your web. Clicking on **Elements** in the window, you'll see a bunch of code, which shows how this web page is build and its written in html format. On the upper-left side, there's a arrow button. Clikcing on it will allow you hover the page to see how each piece of web is build by html code. To better understand how to access specific data, play around with it. 

### Function body
`
[a.attrib["href"] for a in response.css("td.primary_photo a")]
`
may help you get all actors paths. 

To see the result of this command line on yourself, you may read the following **Notice** to run through the code.

In my example, the first element of above command result is *'/name/nm4043618/'*. In order to navigate to the Tom Holland page, we need to add *'https://www.imdb.com/'* as the url's prefix.
Once our actor page is ready, we call the parse_actor_page() and pass the url to it.

### Notice:

To test and see the result, you may open a terminal and run the following.

```python
conda activate PIC16B
cd IMDB_scraper
scrapy shell <url>
```

Replace <url> by the testing url. Then you may type command lines in the terminal to test if the result is what you want.

### code:

```python
def parse_full_credits(self, response):
    '''
    in the All cast & crew link
    get all actors ids, which is a part of their own page link
    call function parse_actor_page and pass the link(completed link) to it
    '''
    prefix = 'https://www.imdb.com'

    # paths to all actors
    actors = [a.attrib["href"] for a in response.css("td.primary_photo a")]

    for actor in actors:
        # completed link
        actorPath = prefix + actor
        yield scrapy.Request(actorPath, callback = self.parse_actor_page)
```


## parse_actor_page(self, response)

We assume we're at an actor page. 

In this function, we want to get the actor's name and his other movies or shows as an actor. Then, we store actor and his movie/show into a dictionary. In order to access these data, we need to find the pattern of the html code by comparing other actor's pages. 

### Actor name

Using **Developer Tool**, we may see that actors' name is inside section **<span class = "itemprop"></span>**. To see if it's correct, we can use the *last section notice* to test it. We can use **response.css()** to access the data from website's html form.


### Moives or shows

The following code might help to access an actor's movies or shows

```python
element.css("::attr(id)")
element.css("div.filmo-row")
element.css("a::text")
```

### Code:

```python
def parse_actor_page(self, response):
    '''
    in each actor own page
    get actor's name and his movies and shows
    store it into a dictionary
    '''
    actor_name = response.css('span.itemprop')[0].css("::text").get()
        
    n1 = 'div#'
    # all ids in a list
    allIds = response.css('div.filmo-category-section').css('::attr(id)').extract()
    n2 = '.filmo-row'
    act_id = []

    # get actor/actress id only
    for i in allIds:
        if i[:5] == "actor":
            act_id.append(i)

    for i in act_id:
        box_name = n1 + i + n2
        movie_or_TV_name = response.css(box_name).css('a')[0].css('::text').get()
        yield{
            "actor" : actor_name,
            "movie_or_TV_name" : movie_or_TV_name
        }   
```

## Save data

Once your code is checked, you may delete the `CLOSESPIDER_PAGECOUNT = 20` in settings.py. And then you may run `scrapy crawl imdb_spider -o results.csv`, which it saves actor_name and movie_or_TV_name into *results.csv*. Notice that **imdb_spider** is the name under our class.



# 3. Analyze data

Creating a table based on *movies.csv*.

```python
import pandas as pd
# save movies.csv into df
df = pd.read_csv("movies.csv")
# get the unique movie/show
movie = df['movie_or_TV_name'].unique()
# stored number of shared actors in a movie/show
num_of_shared_actors = []
for i in movie:
    # get the number of shared actors
    num = df.loc[df['movie_or_TV_name'] == i].shape[0]
    # append it into the list
    num_of_shared_actors.append(num)
# create a dataframe that has columns movie and number of shared actors in it
table = pd.DataFrame(list(zip(movie, num_of_shared_actors)),
               columns =['movie', 'num_of_shared_actors'])
# sort the number of shared actors in descending order and show the first 10 movies
table.sort_values(by=['num_of_shared_actors'],ascending = False).head(10)
```

![moive_table.png]({{site.baseurl}}/images/movie_table.png)


Base on my example result, even though the shared actors isn't too much. But the ranking is pretty reasonable if you saw Spide-Man serie before. So this table would be recommanded based on my favorite movie. 



Link to the GitHub repository:

*https://github.com/chriye/WebScraping*